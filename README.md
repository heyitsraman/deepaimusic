# deepaimusic
Deep Learning concepts and code for Music Applications.

**Part 1:*WAVEFORM PREPROCESSING*

The below waveforms can be obtained by utilising the [preprocess.py file](https://github.com/heyitsraman/deepaimusic/blob/main/preprocess.py) which is intended for preprocessing of a guitar audio file.


![guitar_waveform](https://user-images.githubusercontent.com/94373661/141806285-28e04d63-d2ba-4dae-aaba-fa3a322d5ccc.png)
![guitar_fft](https://user-images.githubusercontent.com/94373661/141806294-b6703aa5-e321-4bee-a587-a4854bbb6fe6.png)
![guitar_spectrogram](https://user-images.githubusercontent.com/94373661/141806268-053dc6c7-aad8-498f-b11e-6c6bbf459490.png)
![guitar_stft(dB)](https://user-images.githubusercontent.com/94373661/141806276-49482066-f871-43a9-865b-dd583c66efb4.png)
![guitar_mfcc](https://user-images.githubusercontent.com/94373661/141806297-1cf01864-7634-4ad4-80c9-aa033417711c.png)


**Part2:*TRAINING DATA SET**

After the waveform processing, we can use the [GTZAN DATASET](https://www.kaggle.com/andradaolteanu/gtzan-dataset-music-genre-classification) for training our model for music classification.
The image and the video results obtained are attached below, belonging to [musicclassify.py](https://github.com/heyitsraman/deepaimusic/blob/main/musicclassify.py)

[Classify](https://user-images.githubusercontent.com/94373661/142231465-a042065b-38bd-47e1-80f1-9d19e0030540.png)
